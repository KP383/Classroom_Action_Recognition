{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f07017f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "import numpy as np    # for mathematical operations\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets.mnist import load_data\n",
    "from numpy import reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout, UpSampling2D\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "# dataset_directory = '/Users/parthkalathia/Desktop/NEW_DATA'\n",
    "dataset_directory = '/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2'\n",
    "# classes_list = ['TALKING', 'HEADDOWN', 'YAWNING', 'MOBILE', 'NORMAL']\n",
    "classes_list =  ['NORMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1626f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(video_path, input_shape):\n",
    "    # Load video and get properties\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    # Initialize array to store frames\n",
    "    all_frames = np.zeros((frame_count, input_shape[1], input_shape[2], input_shape[3]))\n",
    "    frames = np.zeros((input_shape[0], input_shape[1], input_shape[2], input_shape[3]))\n",
    "        \n",
    "    # Read frames and resize\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        frame_resized = cv2.resize(frame, (input_shape[2], input_shape[1]))\n",
    "        all_frames[i] = frame_resized\n",
    "    \n",
    "    # extract equal distance frames from all_frames\n",
    "    j = 0\n",
    "    distance_frame = frame_count//input_shape[0]\n",
    "    for i in range(input_shape[0]):\n",
    "        frames[i] = all_frames[j]\n",
    "        j = j + distance_frame\n",
    "\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    frames = frames / 255.0\n",
    "    \n",
    "    # Close video capture\n",
    "    cap.release()\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173131ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rq/rl4qmvpx22jg0wx1l021ysr80000gn/T/ipykernel_75719/3090441351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(frames[10], interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988bbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_shape):\n",
    "    import random\n",
    "    # Declaring Empty Lists to store the features and labels values.\n",
    "    features = []\n",
    "    labels = []\n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
    "        print(files_list)\n",
    "\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            if file_name == '.DS_Store':\n",
    "                continue\n",
    "            # Construct the complete video path\n",
    "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
    "            print(video_file_path)\n",
    "\n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            frames = preprocess_video(video_file_path, input_shape)\n",
    "          \n",
    "\n",
    "            # Appending the frames to a temporary list.\n",
    "            features.append(frames)\n",
    "        \n",
    "            labels.append(class_index)\n",
    "\n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels) \n",
    "    \n",
    "    return features, labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: NORMAL\n",
      "['N5.mp4', 'N4.mp4', 'N6.mp4', 'N7.mp4', 'N3.mp4', '.DS_Store', 'N2.mp4', 'N1.mp4', 'N23.mp4', 'N22.mp4', 'N20.mp4', 'N21.mp4', 'N19.mp4', 'N18.mp4', 'N24.mp4', 'N17.mp4', 'N15.mp4', 'N10.mp4', 'N11.mp4', 'N13.MOV', 'N12.MOV', 'N9.mp4', 'N8.mp4']\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N5.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N4.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N6.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N7.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N3.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N2.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N1.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N23.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N22.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N20.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N21.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N19.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N18.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N24.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N17.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N15.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N10.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N11.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N13.MOV\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N12.MOV\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N9.mp4\n",
      "/Users/parthkalathia/Desktop/CNN_SCRATCH/FINALDATASET_V2/NORMAL/N8.mp4\n"
     ]
    }
   ],
   "source": [
    "features, labels = create_dataset((16,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf59cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of features :  2\n",
      "Length of labels :  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of features : \", len(features))\n",
    "print(\"Length of labels : \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d7fd79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features :  (50, 16, 256, 256, 3)\n",
      "shape of labels :  (50,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of features : \", features.shape)\n",
    "print(\"shape of labels : \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdd76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(features, one_hot_encoded_labels, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ead463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 16, 256, 256, 32)  2624      \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 16, 256, 256, 64)  55360     \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 8, 128, 128, 64)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 8, 128, 128, 128)  221312    \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 8, 128, 128, 256)  884992    \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 4, 64, 64, 256)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 4, 64, 64, 128)    884864    \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 4, 64, 64, 256)    884992    \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 2, 32, 32, 256)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_11 (Conv3D)          (None, 2, 32, 32, 512)    3539456   \n",
      "                                                                 \n",
      " conv3d_12 (Conv3D)          (None, 2, 32, 32, 64)     884800    \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 2, 32, 32, 32)     55328     \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 16, 16, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                163860    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,584,243\n",
      "Trainable params: 7,584,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "  \n",
    "    model = Sequential()\n",
    "    sample_shape=(16,256,256,3)\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3) ,activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape ,padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(GlobalAveragePooling3d())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(\"Model Created Successfully!\")\n",
    "\n",
    "# Input shape\n",
    "\n",
    "# 5+D tensor with shape: batch_shape + (channels, conv_dim1, conv_dim2, conv_dim3) \n",
    "# if data_format='channels_first' or 5+D tensor with \n",
    "# shape: batch_shape + (conv_dim1, conv_dim2, conv_dim3, channels) if data_format='channels_last'.\n",
    "\n",
    "# Output shape\n",
    "\n",
    "# 5+D tensor with shape: batch_shape + (filters, new_conv_dim1, new_conv_dim2, new_conv_dim3) \n",
    "# if data_format='channels_first' or 5+D tensor with \n",
    "# shape: batch_shape + (new_conv_dim1, new_conv_dim2, new_conv_dim3, filters) if data_format='channels_last'. new_conv_dim1, new_conv_dim2 and new_conv_dim3 values might have changed due to padding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7578c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Early Stopping Callback 9824855926-sahdev bhai\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adding loss, optimizer and metrics values to the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4181d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model_training_history = model.fit(X_train, Y_train , shuffle = True, epochs = 5 , batch_size= 10, validation_split=0.1, callbacks = [early_stopping_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
